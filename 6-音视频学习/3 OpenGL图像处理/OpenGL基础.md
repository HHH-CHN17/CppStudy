### 着色器

[片段插值](https://www.zhihu.com/question/63116687)

着色器(Shader)是运行在GPU上的小程序。这些小程序为图形渲染管线的某个特定部分而运行。从基本意义上来说，着色器只是一种把输入转化为输出的程序。着色器也是一种非常独立的程序，因为它们之间不能相互通信；它们之间唯一的沟通只有通过输入和输出，着色器都是一个**着色器程序**的一部分，通常每个物体（可以理解成VAO）会配置一个着色器程序。

一个片段就是一个像素，它包含了像素的最终颜色，法线等其他属性，片段插值在**光栅化阶段**进行，被应用到片段着色器的所有输入属性上，根据片段在图元中的相对位置决定其绝对位置，并根据相对位置计算该片段的属性值。

![img](./assets/pipeline.png)

在OpenGL程序的**一次绘制调用**中**调用`glDrawArrays()`**绘制一个物体时：

- **顶点着色器**被GPU为每个**顶点**并行地执行一次。

  1. **输入**: 从顶点缓冲对象 (VBO) 中接收**一个顶点**的属性数据 (Vertex Attributes)，例如：顶点位置、颜色、法线、纹理坐标等。同时，它还能接收全局统一变量 (Uniforms)，如模型-视图-投影 (MVP) 变换矩阵。
  2. **处理**: 执行你编写的着色器代码。这个阶段最核心、最基本的任务是进行**坐标变换**，将顶点的局部空间 (Local Space) 位置通过一系列矩阵乘法，转换到最终的裁剪空间 (Clip Space) 位置。它也可以处理其他顶点属性，例如将颜色或纹理坐标直接传递给下一阶段。
  3. **输出**: **必须**输出一个vec4类型的裁剪空间坐标（该坐标依然是齐次坐标）到内置变量 gl_Position。同时，它将其他需要传递给片段着色器的数据（如颜色、纹理坐标）作为 out 变量输出。这些输出值在后续的光栅化阶段会被**插值**。

  顶点着色器只有**一个**。
  它的**执行次数**与你要绘制的物体的**顶点总数**相等。

  ---

- **几何着色器**被GPU为每个**图元**并行地执行一次（如果没有指定几何着色器，则顶点直接进入图元装配阶段）。

  1. **输入**: 从顶点着色器接收一个**完整的图元**。这意味着它一次性接收构成该图元的所有顶点的数据（例如，一个三角形的全部3个顶点及其所有属性）。
  2. **处理**: 执行你编写的着色器代码。这个阶段的独特之处在于它能够**在GPU上动态地创建、修改或销毁几何体**。它可以：
     - 将输入的图元原封不动地传递下去。
     - 修改输入图元的顶点属性。
     - 直接丢弃整个图元（不产生任何输出）。
     - 将一个图元扩展成多个其它图元（例如，将一个点扩展成一个四边形）。
  3. **输出**: 它可以输出**零个、一个或多个**新的图元。这是通过逐个发射（EmitVertex）新的顶点，并将它们组织成新的图元（EndPrimitive）来完成的。输出的图元会被传递到图元装配阶段。

  几何着色器只有**一个**。
  **执行次数**与你要绘制的**图元总数**相等。
  它是一个**可选**阶段，因其可能影响性能，所以不常用。
  的核心能力是**在GPU上即时生成或销毁几何体**。

  ---

- **图元装配**是渲染管线中一个固定的硬件阶段，在一次绘制调用中绘制一个物体时，他只执行一次，但它**不会**等待所有几千几万个顶点都处理完之后才开始工作，它是一个**流式**处理的过程：

  1. **输入**: 从顶点着色器（或可选的几何着色器）阶段接收独立的、已处理过的顶点。
  2. **处理**: 根据你的绘制指令（例如 GL_TRIANGLES），将这些顶点“组装”成指定的图元（例如，每3个顶点组成一个三角形），并进行裁剪。
  3. **输出**: 将一个个完整的图元传递给光栅化阶段。

  图元装配阶段是**一个**整体的功能单元。
  它**持续不断地**工作，接收一个个顶点，将它们组装成图元后立即发送到下一阶段。

  *(注意，图元装配之后，还会经历裁剪和透视除法，将可视范围内的顶点坐标变换为NDC)*

  ---

- **光栅化**和图元装配阶段一样，也是一个**流式**处理的过程：

  1. **输入**: 从图元装配阶段接收一个完整的图元（例如一个三角形）。
  2. **处理**: 计算出这个图元覆盖了屏幕上的哪些像素点。
  3. **输出**: 为每一个被覆盖的像素点，生成一个**片段 (Fragment)**。这个片段包含了进行后续颜色计算所需的所有信息（如插值后的坐标、颜色、纹理坐标等）。

  光栅化阶段是**一个**整体的功能单元。
  它**持续不断地**工作，接收一个个图元，并为它们产生成千上万的片段。

  ---

- **片段着色器**被GPU为**每一个片段**并行地执行一次。

  1. **输入**: 从光栅化阶段接收一个**片段 (Fragment)** 的数据。这个片段是“准像素”，包含了在它所在位置上经过插值计算的所有顶点属性（如颜色、纹理坐标、法线等）。
  2. **处理**: 执行你编写的着色器代码。这个阶段的核心任务是**处理纹理数据**，根据输入数据、纹理、光照信息等，计算出这个片段**最终的颜色**。
  3. **输出**: 输出一个 vec4 类型的颜色值。这个颜色值将进入管线的下一个阶段（深度测试、模板测试、混合），如果通过所有测试，最终会被写入屏幕上的对应像素。

  片段着色器只有**一个**。
  它的**执行次数**与光栅化后生成的**片段数量**相等。一个覆盖半个屏幕的三角形就可能导致它被一定数量的核心并行执行上百万次。

  实际执行时，GPU以2x2的片段块为单位并行处理，但是并不影响我们的结论，见[#纹理](#纹理)

  ---

- **测试与混合**和图元装配阶段一样，也是一个**流式**处理的过程，其性能与结果正确性受物体绘制顺序的影响[#深度测试](#深度测试)：

  1. **输入**: 从片段着色器接收一个片段，这个片段已经有了最终计算出的颜色值和深度值。
  2. **处理 (一系列测试)**:
     - **剪裁测试 (Scissor Test)**: 检查片段是否在你定义的矩形“剪裁”区域内。不在则直接丢弃。
     - **模板测试 (Stencil Test)**: 将片段的模板值与模板缓冲中的值进行比较，根据预设规则决定是否通过或丢弃。这可以用来创建复杂的遮罩效果。
     - **深度测试 (Depth Test)**: 将片段的深度值（Z值）与深度缓冲中对应位置的值进行比较。通常，如果新片段比已有的片段更“远”（深度值更大），它就会被丢弃。这是实现物体正确遮挡关系的关键。
  3. **最终操作 (写入或混合)**:
     - 如果片段通过了所有启用的测试，GPU就会准备将它的颜色写入颜色缓冲区（Framebuffer）。
     - **混合 (Blending)**: 如果开启了混合功能（通常用于渲染半透明物体），新片段的颜色会与颜色缓冲区中已有的颜色按照指定的公式进行**混合**。
     - **写入**: 如果没有开启混合，新片段的颜色会直接**覆盖**掉原来的颜色。

  测试与混合阶段是**一个**整体的功能单元。
  它对光栅化后生成的**每一个片段**都独立、依次地执行上述测试和操作。

### 纹理

[Texture Mapping - 知乎](https://zhuanlan.zhihu.com/p/648468577)

[图形学底层探秘 - 纹理采样、环绕、过滤与Mipmap的那些事 - 知乎](https://zhuanlan.zhihu.com/p/143377682)

- 纹理存储于显存，是一个通用数据缓冲(General Purpose Data Buffer)

- 定义二维图像纹理为 **texture (纹理)**，其**纹理空间**中每个坐标（即**纹素坐标**）对应一个 **texel (纹素)**，

- 图元经过**光栅化阶段**的处理后，会把图元映射为最终屏幕上相应的像素，生成供片段着色器使用的片段。其**像素空间**中每一个**pixel (像素)**都会对应一个**插值后**的顶点坐标和纹理坐标

- **片段着色器可以根据插值后的纹理坐标找到当前片段对应的浮点纹素坐标，并通过纹理过滤采样真正的纹素值作为当前片段的纹理颜色。**

- **纹理坐标**在x和y轴上，范围为0到1之间（注意我们使用的是2D纹理图像）。**使用纹理坐标获取纹理颜色（纹素值）叫做采样**。纹理坐标起始于(0, 0)，也就是纹理图片的左下角，终止于(1, 1)，即纹理图片的右上角。

- **纹理坐标**经过 **corresponder functions (响应函数)** 来到 **texture space (纹理空间)**， 假如某个纹理的贴图分辨率为 256×256 ，那么直接将当前坐标（0.32,0.29）乘上分辨率即可得到坐标 **(** 81.92,74.24) ，去掉小数部分得到坐标 (81,74) ，即 **texel texture (纹素坐标)**。**纹素坐标**对应了**纹理坐标**在**纹理空间**中的**位置**，真正访问纹理贴图的**纹素值**

- 综上（建议至少先完整看一遍教程），注意：

  1. 什么是纹理，纹理坐标，纹素，纹素坐标？

     - 纹理：二维图像纹理

     - 纹理坐标：在uv坐标系下，用于表示纹理中的位置的坐标

     - 纹素：纹理的像素，注意纹素只和纹理的分辨率有关，与纹理坐标无关

     - 纹素坐标：纹理空间中纹素的位置

  2. 哪些名词是连续值？

     答：顶点坐标，纹理坐标

  3. 哪些名词时离散值？

     答：像素，像素坐标，纹素，纹素坐标

  4. 顶点坐标和纹理坐标的对应关系

     答：人工指定顶点坐标（顶点坐标构成的图元在光栅化阶段后会转化为像素坐标）对应哪一个纹理坐标

  5. 什么是**纹理采样**？

     答：当 `纹理分辨率 == 像素输出分辨率` 时，纹理可以直接映射到2D像素输出上，**纹素和像素之间是一一对应的关系，在片段插值时，每一个片段（像素）插值生成的纹理坐标可以转换成唯一一个纹素整数坐标（纹素值）**。**在纹理图片中获取一个纹素值的过程叫纹理采样**

  6. 什么是**纹理过滤**？

     答：当 `纹理分辨率 != 像素输出分辨率` 时，**纹素和像素之间不是一一对应的关系**，`>`时，多个纹素对应一个像素；`<`时，一个纹素对应多个像素。所以需要指定，在片段插值时，每一个片段（像素）的纹理坐标转换成**纹素浮点坐标**后，对应哪一个（加权哪一些）纹素整数坐标对应的纹素值。**这个“寻找”最合适的纹素并通过采样这些纹素计算出最终该片段的像素值的过程叫做纹理过滤**

  7. 什么是**多级渐远纹理**（Mipmap）

     答：我们已经知道了在采样纹理时，纹理大小跟图形大小接近才会有好的显示效果，因此便有了Mipmap技术。Mipmap的原理是预先生成一系列以2为倍数缩小的纹理序列，在采样纹理时根据图形的大小自动选择相近等级的Mipmap进行采样

  8. 片段着色器如何确定当前片段对应的Mipmap等级

     答：**GPU通过计算纹理坐标在相邻像素上的变化率来自动完成这件事。**

     这个过程对程序员来说是**隐式**和**自动**的，当你调用 texture() 函数时，GPU硬件会为你搞定一切。

     具体实现：GPU在处理片段时，通常是**以2x2的片段块为单位并行处理的**。这使得GPU可以访问相邻片段的信息

     但是“片段着色器运行的次数=片段的个数”这个结论依然成立，原因如下：

     - **逻辑模型**

       OpenGL API 和 GLSL 语言向你呈现的是一个简单、清晰的抽象模型：

       - 光栅器每生成一个片段，就会为它**独立地**调用一次片段着色器。
       - 每一次着色器调用都是一个**隔离的**环境，它只能访问自己的输入数据（插值后的顶点属性，gl_FragCoord等）和全局的uniforms。
       - 在这个模型下，**执行次数绝对等于片段数量**。

     - **物理实现**

       在硬件层面，为了达到极致的效率，GPU并不会真的一个个地独立执行。它会这样做：

       - **分组执行 (Lock-step Execution)**: GPU会将片段分组，通常是**2x2的“四边形”(Quad)**，或者更大的**“线程束”(Warp/Wavefront)**，比如32或64个片段。同一个组内的所有片段会**同时、同步地**执行**同一个**着色器指令。
       - **硬件特性**: 正是因为这种2x2的分组是最小的执行单元，GPU硬件才能轻松地访问到“邻居”的数据。计算导数（纹理坐标的变化率）的函数，如 dFdx() 和 dFdy()，实际上就是利用了这个硬件特性，它是一个非常快速的硬件指令，用于获取组内相邻片段的值的差异。

     - **调和“矛盾”**

       这里的关键点是：**硬件的物理实现，是为了在不破坏逻辑模型的前提下，进行最大化的性能优化。**

       - 虽然一组片段被捆绑在一起执行，但每个片段的计算仍然是使用**它自己的数据**。你的变量a和旁边片段的变量a在内存中是完全独立的。
       - 所以，从结果来看，它**等同于**为每个片段都独立运行了一次。硬件保证了这种等效性。
       - Mipmap等级的选择（以及其他依赖导数的函数）是这个模型中一个罕见的“例外”，硬件开放了一个特殊的指令，允许你窥视一下邻居的数据，但这并不会破坏整个模型的独立性。

  9. 纹理坐标和纹素坐标的对应关系（纹理坐标通过转换对应一个浮点纹素坐标，注意浮点纹素坐标不是纹素对应的那个纹素整型坐标）

  10. 纹素整型坐标和纹素值的对应关系（一个纹素整型坐标对应一个纹素值）

  11. 纹理坐标和纹素值的对应关系（看5，6，7）

- 除了以上几点，编程时还需注意：

  1. 图像资源与纹理的关系

     答：用图像资源生成纹理，生成之后图像资源便没了作用

  2. 纹理单元与采样器的关系

     答：**一个纹理的位置值通常称为一个纹理单元**，我们需要通过`glUniform1i()`告诉采样器去指定的纹理单元取纹理数据

     也就是说：纹理单元作为一个桥梁，告诉OpenGL当前绑定的纹理需要传给哪个纹理单元，以及采样器需要读哪个纹理单元中的纹理。

  3. 纹理与纹理单元的关系

     生成纹理后，OpenGL还不知道这个纹理对应的是哪个纹理单元，所以需要将纹理绑定到对应的纹理单元，这样后续采样器取值时就能够获取到正确的纹理。

  4. OpenGL纹理采样全过程：

     首先我们会加载一个图像，用这个图像生成一个纹理，并将这个纹理传给当前激活的纹理单元（假设是`GL_TEXTURE0`），然后设置片段着色器中的`sampler2D`的值为0。随后在渲染过程中，当渲染管线运行到片段着色器阶段时，`sampler2D`便会从0号纹理单元中读取纹理数据，然后通过`texture()`函数，我们会将（插值的）纹理坐标对应那些纹素进行过滤，环绕，获取到该像素坐标对应的纹理颜色。

### 深度测试

- 提前深度测试

  解释：**在执行开销巨大的片段着色器之前，先进行深度测试。**
  具体来说：

  1. **传统流程**：
     光栅化 -> 片段着色器 -> 深度测试
     - 缺点：即使一个片段最终会被其他物体遮挡（即在深度测试中失败），GPU依然会为它完整地运行一次片段着色器，造成了计算资源的浪费。
  2. **提前深度测试流程**：
     光栅化 -> **深度测试** -> 片段着色器
     - 优点：如果一个片段在光栅化后，通过深度比较发现它已经被遮挡，GPU会**立即丢弃**这个片段，**不再为它执行后续的片段着色器**。 这能极大地提升渲染性能，尤其是在有大量遮挡的复杂场景中。

  **关键限制**

  文档中也明确指出，要让提前深度测试生效，有一个重要限制：**你不能在片段着色器中手动修改片段的深度值**（例如写入gl_FragDepth）。
  因为一旦你这样做，GPU就无法在运行片段着色器**之前**预知最终的深度值，这个优化就会自动失效，流程退回至传统方式。

- 绘制顺序对测试与混合阶段的影响

  **核心思想**：**测试与混合**阶段并非在所有绘制指令结束后才执行一次，而是**为每一次绘制调用（Draw Call）都独立、完整地运行一次**。它是一个**有状态**的过程，每一次运行都会读取并可能修改帧缓冲（颜色和深度缓冲区），从而直接影响下一次绘制调用的结果。

  可以把帧缓冲想象成一块正在创作中的油画画布。每一次绘制调用，都是画家在画布上新画一层。

  1. 对于不透明物体（主要影响：深度测试）

     对于不透明物体，绘制顺序主要影响**性能**，而非最终画面的正确性。

     - **运行机制**：
       1. 当第一个物体被绘制时，它的片段在通过深度测试后，会将其颜色写入**颜色缓冲**，并将其深度值写入**深度缓冲**。
       2. 当第二个物体被绘制时，它的片段会与**深度缓冲中已存在的值**（即第一个物体留下的深度值）进行比较。
     - **对性能的影响**：
       - **先画远，再画近**：远处的物体先通过深度测试，写入颜色和深度。然后近处的物体再通过测试，**覆盖**掉远处物体的颜色。被覆盖部分的片段着色器被**浪费**了。
       - **先画近，再画远**：近处的物体先写入深度。当绘制远处物体时，被遮挡的部分在**提前深度测试（Early-Z）**阶段就因深度值更大而失败，GPU会直接丢弃这些片段，**避免了运行昂贵的片段着色器**，效率极高。

     ---

  2. 对于半透明物体（主要影响：混合）

     对于半透明物体，绘制顺序直接影响**最终画面的正确性**。

     - **运行机制**：
       混合操作需要将新片段的颜色（**源颜色**）与颜色缓冲中已存在的颜色（**目标颜色**）相结合。混合公式 最终颜色 = 源颜色 * Alpha + 目标颜色 * (1 - Alpha) 是**非交换**的，即源和目标互换，结果会完全不同。
     - **对正确性的影响**：
       - **正确顺序（从远到近画）**：先画后面的墙壁，它的颜色成为**目标颜色**。再画前面的玻璃，玻璃的颜色作为**源颜色**与墙壁颜色混合，得到正确的半透明效果。
       - **错误顺序（从近到远画）**：先画前面的玻璃，它会与背景色混合。然后画后面的墙壁，由于墙壁是不透明的且深度写入默认开启，它会直接通过深度测试**覆盖**掉之前画好的玻璃。结果完全错误。

     ---

  ### 总结

  | 物体类型       | 绘制顺序如何影响“测试与混合”阶段                             |
  | -------------- | ------------------------------------------------------------ |
  | **不透明物体** | 每一次绘制调用都会更新深度缓冲区，影响后续调用的**深度测试结果**。顺序不影响最终画面，但**严重影响性能**。 |
  | **半透明物体** | 每一次绘制调用都会更新颜色缓冲区，这个颜色会成为后续调用进行**混合操作时的“目标颜色”**。顺序**直接决定最终画面的正确性**。 |

### 帧缓冲FBO

[#代码](D:\1_Code\Visual Studio 2022\LearnOpenGL\7_Framebuffers\LearnOpenGL)

1. 什么是帧缓冲？

   **核心思想**:

   到目前为止，我们所有的绘制操作都是直接在**默认帧缓冲 (Default Framebuffer)** 上进行的——也就是你创建窗口时，窗口系统自动为你管理的那个“画布”，它的内容最终会显示在你的屏幕上。

   **帧缓冲 (Framebuffer Object, FBO)** 允许我们**创建自己的、额外的、离屏的 (Off-screen) 画布**。我们可以将场景渲染到这些自定义的画布上，而不是直接渲染到屏幕。

   **一个FBO本质上是一个容器**，它本身不存储任何像素数据。它只是一个“插座”，你需要创建并**附加 (Attach)** 一些可存储数据的对象上去，这些对象被称为**附件 (Attachments)**，示意图如下：

   <img src="assets/eb435fbd8686fbe7789c6310aaf1d994.jpeg" alt="img" style="zoom: 67%;" />

   ---

2. 帧缓冲的附件 (Attachments)

   一个完整的帧缓冲通常需要附加以下两种类型的对象：

   1. **颜色附件 (Color Attachment)**:
      - **作用**: 存储**颜色**数据。所有片段着色器计算出的颜色值都会被写入到这里。
      - **实现方式**: 通常是一个**纹理 (Texture)**。将场景渲染到纹理上，意味着我们可以像使用普通纹理一样，在后续的渲染步骤中对这个渲染结果进行采样（例如，实现后期处理效果）。
   2. **深度/模板附件 (Depth and Stencil Attachment)**:
      - **作用**: 存储**深度**和**模板**信息，以便进行深度测试和模板测试。
      - **实现方式**:
        - **纹理 (Texture)**: 同样可以将深度信息存储在纹理中，以便后续采样。
        - **渲染缓冲对象 (Renderbuffer Object, RBO)**: 这是一种更专门、更高效的存储格式。它的数据不能像纹理一样被着色器直接采样，但对于只写（例如，只用于深度测试）的场景，它的性能通常比纹理更好。

   ---

3. 使用帧缓冲的基本流程

   使用FBO进行离屏渲染，通常遵循以下三个步骤：

   - **Step 1: 创建与设置**

     1. **创建FBO**: 调用 `glGenFramebuffers()` 创建一个帧缓冲对象。
     2. **创建附件**:
        - 创建一个**纹理**作为颜色附件 (`glGenTextures`, `glTexImage2D`, ...)。
        - 创建一个**渲染缓冲对象**作为深度/模板附件 (`glGenRenderbuffers`, `glRenderbufferStorage`, ...)。
     3. **绑定FBO**: 调用 `glBindFramebuffer(GL_FRAMEBUFFER, fbo)` 激活我们自己的FBO。
     4. **附加附件**:
        - 调用 `glFramebufferTexture2D()` 将纹理附加到FBO的颜色附件点上。
        - 调用 `glFramebufferRenderbuffer()` 将RBO附加到FBO的深度/模板附件点上。
     5. **检查完整性**: 调用 `glCheckFramebufferStatus()` 确保FBO的配置是完整且有效的。
     6. **解绑FBO**: 设置完成后，通过 `glBindFramebuffer(GL_FRAMEBUFFER, 0)` 切回默认帧缓冲，以防意外修改。

     ---

   - **Step 2: 渲染阶段 (离屏渲染)**

     1. **绑定FBO**: `glBindFramebuffer(GL_FRAMEBUFFER, fbo)`。现在，所有后续的渲染指令都会绘制到我们附加到`fbo`上的纹理和RBO中，而不是屏幕。
     2. **清空画布**: `glClear()` 清空我们FBO的附件。
     3. **绘制场景**: 像平常一样，调用你的 `glDrawArrays` 或 `glDrawElements` 来绘制你的3D场景。
     4. **解绑FBO**: `glBindFramebuffer(GL_FRAMEBUFFER, 0)`。渲染完成后，切回默认帧缓冲。

     ---

   - **Step 3: 使用渲染结果 (后期处理)**

     1. **清空屏幕**: `glClear()` 清空默认帧缓冲（屏幕）。
     2. **使用纹理**: 现在，我们在第一步中创建的、并已在第二步中被渲染上场景图像的**纹理**，可以像任何普通纹理一样被使用。
     3. **绘制一个覆盖全屏的四边形**: 绘制一个简单的矩形，让它正好铺满整个屏幕。
     4. **绑定并采样纹理**: 在这个四边形的片段着色器中，绑定我们之前渲染好的场景纹理，并对其进行采样。
     5. **应用效果**: 在采样纹理后，可以在片段着色器中对颜色进行各种处理，例如：
        - **灰度化**: `color.r * 0.299 + color.g * 0.587 + color.b * 0.114`
        - **反相**: `1.0 - color`
        - **核效果 (Kernel Effects)**: 如模糊、锐化等，通过对纹理周边像素进行多次采样。

### 像素缓冲PBO



### 基础光照



### EGL



### OpenGL中的多线程



### QT中的OpenGL

